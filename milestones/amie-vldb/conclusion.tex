% !TEX root = main.tex

In this paper, we have presented AMIE, an approach to mine Horn rules on large RDF knowledge bases. AMIE is based on a formal model for rule mining under the Open World Assumption, a method to simulate counter-examples, and a scalable mining algorithm. In contrast to state-of-the-art approaches, AMIE requires no input other than the KB and does not need configurations or parameter tuning.

We have extended AMIE to AMIE+ by a series of pruning and query rewriting techniques, both lossless and approximate.
As our extensive experiments have shown, AMIE+ runs on millions of facts in only a few minutes and outperforms state-of-the-art approaches not only in terms of runtime,
but also in terms of the number and quality of the output rules.
If we combine these rules with simple heuristics for type checking and joint prediction, we can use them to predict facts with a precision of about 70\%.
%Our confidence measure can reasonably predict the precision of the rules.
%Additionally, we describe AMIE+ which introduces a series of runtime improvements over AMIE, enabling rule mining over very large knowledge bases, with more than 10M facts and thousands of relations.
%\comment{Chris}{Perhaps write some impressive result here.}

For future work, we aim to develop better joint inference approaches based on the rules mined by AMIE. We also aim to
extend the set of rules beyond the language of closed Horn rules,
so that even more facts can be predicted.

% For future work, we aim to use instance information (types) to improve the precision of rules. We also aim to explore the synergy when multiple rules predict the same fact, and to extend the set of rules beyond the language of closed Horn rules,
% so that even more non-obvious facts can be predicted.
%We also aim to explore the synergies when several rules predict the same fact, and extend the set of rules beyond Horn rules, so that even more complex facts and hidden knowledge can be predicted.%\\[-0.5cm]
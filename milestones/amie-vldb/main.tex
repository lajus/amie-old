%%%%%%%%%%%%%%%%%%%%%%% file template.tex %%%%%%%%%%%%%%%%%%%%%%%%%
%
% This is a general template file for the LaTeX package SVJour3
% for Springer journals.          Springer Heidelberg 2010/09/16
%
% Copy it to a new file with a new name and use it as the basis
% for your article. Delete % signs as needed.
%
% This template includes a few options for different layouts and
% content for various journals. Please consult a previous issue of
% your journal as needed.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% First comes an example EPS file -- just ignore it and
% proceed on the \documentclass line
% your LaTeX will extract the file if required
% \begin{filecontents*}{example.eps}
% %!PS-Adobe-3.0 EPSF-3.0
% %%BoundingBox: 19 19 221 221
% %%CreationDate: Mon Sep 29 1997
% %%Creator: programmed by hand (JK)
% %%EndComments
% gsave
% newpath
%   20 20 moveto
%   20 220 lineto
%   220 220 lineto
%   220 20 lineto
% closepath
% 2 setlinewidth
% gsave
%   .4 setgray fill
% grestore
% stroke
% grestore
% \end{filecontents*}
%
\RequirePackage{fix-cm}
%
%\documentclass{svjour3}                     % onecolumn (standard format)
%\documentclass[smallcondensed]{svjour3}     % onecolumn (ditto)
%\documentclass[smallextended]{svjour3}       % onecolumn (second format)
\documentclass[twocolumn]{svjour3}          % twocolumn
%
\smartqed  % flush right qed marks, e.g. at end of proof
%
\usepackage[
        pdftex,
        %letterpaper,
	a4paper=true,
	bookmarks=true,
        bookmarksopen=false,
        bookmarksnumbered=true,
        colorlinks=true,
	linkcolor=blue,
	citecolor=blue,
	filecolor=blue,
	urlcolor=blue,
        pdfauthor={Luis Galarraga, Christina Teflioudi, Katja Hose, Fabian M. Suchanek},
        pdftitle={AMIE: Association Rule Mining under Incomplete Evidence in Ontological Knowledge Bases},
        plainpages=false,
        pdfpagelabels,
]{hyperref}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{cite}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage{caption}
\usepackage{footnote}
\usepackage{balance}
\usepackage{bm}
\usepackage[english]{babel} 

\newcommand{\indented}[1]{
\begin{tabbing}
hallo\=\+\kill
#1
\end{tabbing}
}

% Puts a figure there where you put the command -- not somewhere else
% \newcommand{\ffigure}[4]{% \ffigure{Table | Figure}{label}{title}{imagecommand}
%   \refstepcounter{figureCounter} \label{#2}
%   {\centering
% 	  #4\ \nopagebreak[4]\\\nopagebreak[4]
% 	  {\bf #1 \ref{#2}: #3}\ \\[0.3cm]
%   }
% }

%\newcommand{\www}[1]{{\color{blue}#1}}
\newcommand{\www}[1]{#1}


\newcommand{\comment}[2]{{\color{red}{#1: #2}}}
% \newcommand{\comment}[2]{}

\renewcommand{\paragraph}[1]{\noindent\textbf{#1.}}
\renewcommand{\vec}[1]{\overrightarrow{#1}}
\newcommand{\ignore}[1]{}
%\newcounter{figureCounter}

%
% \usepackage{mathptmx}      % use Times fonts if available on your TeX system
%
% insert here the call for the packages your document requires
%\usepackage{latexsym}
% etc.
%
% please place your own definitions here and don't use \def but
% \newcommand{}{}
%
% Insert the name of "your journal" with
% \journalname{myjournal}
%

\sloppy

\begin{document}

% cover letter
% \begin{figure*}[t!]
% \hspace{.1\textwidth}
% \begin{minipage}{.8\textwidth}
%   \begin{centering}
% %    \LARGE\textbf{Summary of changes}
%     \LARGE\textbf{Cover letter}
%     \vspace{.3em}
%   \end{centering}
% 
%   \large
% %This article is an extended version of our WWW paper on rule mining in ontological knowledge bases~\cite{amie}.
% %We revised the paper throughout and included several new results and  experiments.
% This article is based on our previous work~\cite{amie} on rule mining in ontological knowledge bases that we published at the WWW conference 2013 and was awarded 
% the best student paper award. The work presented in this article extends the basic approach in several ways and includes new results and experiments.
% 
% The original WWW paper introduced AMIE, a system for rule mining under incomplete evidence in ontological knowledge bases (KBs).
% Although AMIE was able to successfully mine rules from KBs (such as YAGO2~\cite{yago2}) for which other state-of-the-art ILP systems fail, it was still unable to run in acceptable time over very large KBs (such as YAGO2s~\cite{yago2s} and DBpedia 3.8~\cite{dbpedia}).
% 
% %In this article, we present additionally AMIE+. AMIE+ (Sec.~\ref{sec:improvements}) introduces a series of runtime improvements over AMIE.
% In this article, we present AMIE+, an approach that introduces a series of improvements over AMIE (Sec.~\ref{sec:improvements}).
% We describe sophisticated query rewriting, pruning, upper bounds on the rule confidence, and confidence score approximations, which help AMIE+ explore the search space more efficiently.
% %takes advantage of the maximum rule length to prune the search space, makes use of query rewriting and caching when possible,
% %and avoids the execution of expensive queries for less promising rules by the use of a confidence upper bound and confidence approximation.
% Our experimental results show that AMIE+ provides a huge speedup over AMIE while producing comparable results.
% In addition, we conducted a qualitative evaluation (Sec.~\ref{pcaEvaluation}) in order to investigate the basic assumption of AMIE, the Partial Completeness Assumption. %Assumption (PCA), leads to unsatisfactory results.
% %We report our findings and suggest possible solutions that strengthen AMIE's performance even when PCA behaves suboptimal.
% % Fabian: Let's not emphasize problems early on...
% We also re-organized the paper, added more background on alternative approaches,  and improved the overall presentation.
% \end{minipage}
% \end{figure*}

\begin{figure*}[t!]
\hspace{.1\textwidth}
\begin{minipage}{.8\textwidth}
  \begin{centering}
   \LARGE\textbf{Summary of changes}
    \vspace{.3em}
  \end{centering}
  \large  
  We thank the reviewers for their valuable comments and feedback. We revised our work to address their comments. Changes include:
  
  \begin{itemize}
  
    \item \textit{R1: my main concern with this paper is the very poor precision of the predicted statements produced by the mined rules (35\%-45\%)\\  }
    The original AMIE paper presents the PCA assumption as a better alternative to the CWA used in traditional rule mining systems. In order to support this claim,
    we devised an overly simple experiment: We directly use the rules to draw predictions without any further verification
    step and evaluated their precision.
%     This experiment was good enough to compare the CWA and the PCA, but it was not meant to show the end performance 
%     in terms of quality that one could get from such a system.
    Such experimental setup was designed to compare the CWA and the PCA, rather than introducing a new rule-based
    inference approach. In real applications one would take advantage of the type information and use 
    a more principled inference method (e.g. MLNs) to quantify the confidence of facts produced by multiple rules, 
    attach probabilities to predictions and prune low-probability facts. In Sec.~\ref{subsubsec:std_vs_pca}, we include 
    an experiment in which AMIE makes uses of the type information (but still does simple deduction of facts)
    and the precision curve already moves significantly higher. 
    
  
   \item \textit{R1: the main proposed heuristic (which contributes most to the  speed-up) is an ad-hoc approximation of 
   the PCA confidence for a specific type of 3-atom rules, being not trivial to generalize it to any kind of rule. 
   (Indeed, experiments are limited to 3-atom rules)\\
   R2: the rules that this technique can be applied to are still a bit limited. \\   }
   In Sec.~\ref{subsec:pruningbyapprox} we introduce a formula for the confidence approximation for longer rules
   
   \item \textit{R2: when the article introduces the notation of |rng(directed)|, it says it "is the number of distinct directors in the range of directed". I strongly suspect there is a typo here. \\  }
   True. Corrected.
   
   \item \textit{R2: There are two expressions in 6.2.2: one computes \#x1 per x0 and the other compute \#x2 per x1. 
   Given the symmetry between $r_0$ and $r_1$ (directed and hasActor in the example), we can switch the two expressions. 
   That is, we can use the expression with ov and |rng| to compute \#x2 per x1 and use the other expression for \#x1 per x0. 
   Is there any preference of one way over another? How does AMIE+ choose?\\  }
   
   
   
   
   
   
   \item \textit{R1: authors compare their approach to two ILP methods which were proposed at earlier 2000. More robust and grounded method for mining relational data have been proposed since then. A fair
comparison to these methods needs to be carried out in order to demonstrate the difficulty of the problem and how far the precision scores are from these methods.\\  }
We would be very grateful for any pointer to work comparable to AMIE that we missed from our related work and experiments section.

   
   
     \end{itemize}
\end{minipage}
\end{figure*}

\begin{figure*}[t!]
\hspace{.1\textwidth}
\begin{minipage}{.8\textwidth}
\large 
     \begin{itemize}
   
      \item \textit{R2: the queries presented throughout the paper (mainly in Section 5.3 and 5.4) to compute the support appear to be incorrect. [...]
      The article should carefully re-examine and re-write those SQL and SPARQL queries\\  }
      
      \item \textit{R2: The first optimization avoids evaluating non-closed rules in the last iteration. The article lacks experimental results to show the effect of this technique.\\  }
      
      \item \textit{R2: The second optimization stops expanding a rule if it has a 100\% PCA confidence. I found this a bit confusing. 
      Since AMIE+ does not compute the PCA confidence during expanding rules, then the question is how AMIE+ identifies whether a rule has a 100\% PCA 
      confidence or not and whether the PCA confidence is actually computed. The article needs to clarify how and when this optimization can be applied.\\  }
      
      \item \textit{R2: Using the third optimization technique to expand a rule, AMIE+ chooses the same frequent relations for new atoms as in the last iteration 
      when the rule is built if the rule is equivalent to its parent rule. 
      The article uses an example to describe this technique, but lacks some formal definitions and discussions. 
      The article should have more details to give answers to several critical questions: a) How to determine whether a new query can be rewritten to an old one? 
      b) How the query rewriting is done? What rules are used in the query rewriting? 
      c) Can this technique be applied to general rules? Or does AMIE+ only use this this technique for those rules that have the exact form as the given example?.\\ }
      
      
\end{itemize}
\end{minipage}
\end{figure*}

\begin{figure*}[t!]
\hspace{.1\textwidth}
\begin{minipage}{.8\textwidth}
\large 
\begin{itemize}
      
      \item \textit{R2: The fourth optimization technique uses a confidence threshold to filter out generated closed rules that have a 
      small confidence upper bound to avoid expensive computations for its actual confidence. 
      This technique can only be used for rules with exactly two body atoms of the same predicate sharing one variable. 
      This restriction limits the benefits gained from applying this technique. 
      As shown in Table 7 in the experiments section, we can see that there is not a big improvement in execution time and only a small amount of rules may be removed.\\  }
      
      \item \textit{R2: The experiments should give a breakdown of the execution time of AMIE+ on the two rule mining steps and show the performance improvement on the respective step for each optimization technique.\\  }
      
      
      \item \textit{R2: The article gives experimental results on the quality of rules to compare the PCA confidence with the standard confidence in Section 7.4.2. 
      It runs AMIE on the YAGO2 dataset, and validates the predictions that are not in the dataset. If I understand this correctly, 
      the predictions are made on the training set YAGO2, and those that do not exist in the training set are validated in a newer YAGO2s version or manually. 
      To evaluate the prediction capability of a method, it is better to separate the training and the testing set.  
      The article, however, generates the rules and uses the rules to generate predictions on the same dataset. 
      Therefore, a possibly better design is to run AMIE on a training subset of YAGO2, apply those rules to a separate testing subset of YAGO2 to generate new predictions and 
      validate each prediction on YAGO2 or in other ways. Similarly, when the article compares AMIE+ with other methods, the experiments should contain a type 
      of experiments that separate the training and the testing data and use recalls as well as precisions as metrics. \\  }
      As the reviewer points out, we use YAGO2 as a training set on which AMIE learns the rules and then keep for the evaluation (test set) only the produced facts that do not exist in the training set.
      In other words, with our setup training and testing takes place on disjoint sets of data. 
      Taking a sample from YAGO2 to use it for test data, as the reviewer suggests, can be problematic. The implicit assumption behind random sampling is that incompleteness in 
      web-extracted KBs appears in a random way, which is not true. If we knew exactly how incompleteness works (and therefore how to sample our KB properly), we would have solved the original
      problem that we are trying solve with AMIE.
      
      
      \end{itemize}
\end{minipage}
\end{figure*}

\begin{figure*}[t!]
\hspace{.1\textwidth}
\begin{minipage}{.8\textwidth}
\large 
     \begin{itemize}
     
      \item \textit{R2: In Section 4.4.1, it is not quite accurate to say that "Thanks to the FUN-property, the assumption is also true for inverse-functional relations." 
      Strictly speaking, the assumption is true for inverse-functional relations only when we know the complete domain of the y variable in r(x, y). 
      If there is an unknown value of y, we clearly cannot know whether r(x, y) is true for r, a given value x, and the unknown value of y. 
      The article needs to make this implicit assumption explicit that the domain for each variable is complete. \\  
      R3: The FUN-property of a KB is problematic, it assumes something about the major KBs are written which may be factually true (e.g. in YAGO or DBPEDIA) 
      but should really be verified on case-by-case (e.g., what about biological KBs?) so I think it must be contextualized to the KBs under investigations and be presented as a 
      factual observation which holds in that limited setting.  \\        
      }
      The FUN-property states that relations in KBs can be swapped with their inverses (e.g., hasCitizen with isCitizenOf) such that all relations in the KB appear to have higher functionality
      than inverse functionality. The PCA confidence formula derived later will predict for each predicate $r(x,y)$ the less functional variable $y$ given a relation $r$ and the most functional variable $x$.
      By introducing the FUN-property (and re-writting the relations) we avoid having 2 versions of the PCA confidence formula (case 1 if $x$ is more functional, case 2 if $y$ is more functional).
      Since the FUN-property created confusion, we completely removed it and re-phrased the corresponding parts. 
      
      \item \textit{R2: The three operators used in the rule mining can actually be reduced to a single and simpler operator: add a new atom with a shared variable with the current rule. \\  }
      
      \item \textit{R2: The rdf:type relationship in a KB can be used to derive the type for each argument of a predicate. 
      The information should be used, if it was not used, in the mode setting of Aleph to facilitate the learning.\\  }
      Type information was indeed used for Aleph to facilitate the learning. Otherwise, Aleph cannot work. 
      In this revision, we also include an experiment in which we use type information for AMIE. 
      
         \end{itemize}
\end{minipage}
\end{figure*}

\begin{figure*}[t!]
\hspace{.1\textwidth}
\begin{minipage}{.8\textwidth}
\large 
     \begin{itemize}
     
      \item \textit{R3: why AMIE+? If one looks at the 4-atom rules of Table 2, none of them seems very good. 
      E.g., in rule 1, why is the rule (living in X) -> (citizen of X) stronger because a citizen imports and exports the same goods? [...] 
      If these are the only 4 examples of good new rules produced by AMIE+,  I am really not impressed.\\  }
      
      
     \item \textit{R3:  Algorithm 1 is too high level and as such it leaves too much unexpressed (e.g. "execute in parallel", "is not pruned for output").\\  }
     
     
      \item \textit{R3:  SQL and SPARQL are presented at page 11 only to say that they are discarded for a custom implementation.\\  }
      
      
      \item \textit{R3:  The "vanilla in-memory database" implementation is too informally described (e.g.: each "index is a map from the first item to a map from the second item to a set of the third item": 
      a more formal description and a figure, please!\\  }
      
      
        \end{itemize}
\end{minipage}
\end{figure*}

\begin{figure*}[t!]
\hspace{.1\textwidth}
\begin{minipage}{.8\textwidth}
\large 
     \begin{itemize}   
      
      \item \textit{R3: The wide set of experiments is good, but it recaps in 7.1 and 7.2 ``obsolete'' results of WWW where AMIE was shown superior to other systems - 
      in spite of the fact that now AMIE+ is present and it is superior to AMIE. \\  }
      We re-wrote the experiments section such that we can focus more on the performance of AMIE+. Detailed runtime comparisons with other systems (WARMR and Aleph)
      were removed, and the reader is pointed to the original AMIE paper for more details.

      


      
      \item \textit{R3: Rules are introduced with no limitations on their syntax but then, under the strange section heading "language biases", 
      we discover that rules should be connected, closed, nonreflexive, and can be recursive (no example provided).       
      There exists a better way of defining rule syntax \& constraints! Incidentally, using a closed rule as example of generic rule does not help the reader's intuition. \\  }

      \item \textit{R3: The discussion on support and coverage is rather clear (but an example would not hurt).\\  }
      
      
      \item \textit{R3: I would like to understand sooner that 4.3 is a discarded and useless digression and I would appreciate a deeper discussion of Section 4.4, possibly with examples.\\  }
      
      
   
  \end{itemize}
\end{minipage}
\end{figure*}

\title{Fast Rule Mining in Ontological Knowledge Bases\\ with AMIE+}


\author{Luis Gal\'arraga\and
        Christina Teflioudi \and Katja Hose \and Fabian M. Suchanek
}

%\authorrunning{Short form of author list} % if too long for running head

\institute{L. Gal\'arraga and F. M. Suchanek \at
              T\'el\'ecom ParisTech \\
              Paris, France\\
              E-mail: \{galarrag, suchanek\}@enst.fr \\
           \and
           C. Teflioudi\at
              Max Planck Institute for Informatics\\
			  Saarbr\"ucken, Germany \\
	      E-mail: chteflio@mpi-inf.mpg.de
			  \and
	       K. Hose \at
		   Aalborg University\\
		   Aalborg, Denmark \\
	      E-mail: khose@cs.aau.dk
}

\date{Received: date / Accepted: date}
% The correct dates will be entered by the editor


\maketitle

\begin{abstract}
Recent advances in information extraction have led to huge knowledge bases (KBs), which capture knowledge in a ma\-chine-readable format.
Inductive Logic Programming (ILP) can be used to mine logical rules from these KBs, such as ``If two persons are married, then they (usually) live in the same city''.
While ILP is a mature field, mining logical rules from KBs is difficult, because KBs make an open world assumption.
This means that absent information cannot be taken as counterexamples.
AMIE~\cite{amie} shows how rules can be mined effectively from KBs even in the absence of counterexamples.
In this paper, we show how this mining process can be optimized to support even large-scale KBs with more than 12M statements -- in a matter of hours instead of days.
Extensive experiments show how our new approach, AMIE+, extends to areas of mining that were previously beyond reach.
\keywords{Rule Mining \and Inductive Logic Programming \and ILP \and Knowledge Bases}
\end{abstract}


%- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\section{Introduction}
\label{sec:introduction}
\input{introduction}


%- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\section{Related Work}
\label{sec:relatedWork}
\input{relatedwork}


%- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\section{Preliminaries}
\label{sec:preliminaries}
\input{preliminaries}


%- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
% \section{Mining Model}
% \label{sec:model}
% \input{model}

%- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\section{Confidence Measures}
\label{sec:pca}
\input{pca}


%- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\section{AMIE}
\label{sec:alg}
\input{algorithm}


%- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\section{Scalability Improvements: AMIE+}
\label{sec:improvements}
\input{improvements}


%- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\section{Experiments}
\label{sec:experiments}
\input{experiments}


%- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\section{Conclusion}
\label{sec:conclusion}
\input{conclusion}

%\begin{acknowledgements}
%If you'd like to thank anyone, place your comments here
%and remove the percent signs.
%\end{acknowledgements}

% BibTeX users please use one of
%\bibliographystyle{spbasic}      % basic style, author-year citations
\balance
\bibliographystyle{spmpsci}      % mathematics and physical sciences
%\bibliographystyle{spphys}       % APS-like style for physics
\bibliography{references}   % name your BibTeX data base


\end{document}
% end of file template.tex
% !TEX root = main.tex

After having outlined the basic definitions and the mining model in Sections~\ref{sec:preliminaries} and \ref{sec:model}, we now outline the core algorithm of our framework and its implementation. 

%- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
\subsection{Algorithm}
\paragraph{Goal} Our goal is to mine rules of the form defined in Section~\ref{sec:preliminaries}.
One of the main problems of any mining approach is to find an efficient way to explore the search space. The naive algorithm of enumerating all possible rules is infeasible for large KBs.
Hence, we explore the search space by iteratively extending rules by \emph{mining operators}.

\paragraph{Mining Operators} 
We see a rule as a sequence of atoms. The first atom is the head atom and the others are the body atoms. In the process of traversing the search space, we can extend a rule by using one of the following operators:
\begin{enumerate}
\item \textbf{Add Dangling Atom ($\mathcal{O}_D$})\\
This operator adds a new atom to a rule. The new atom uses a fresh variable for one of its two arguments. The other argument (variable or entity) is shared with the rule, i.e., it occurs in some other atom of the rule. 
\item \textbf{Add Instantiated Atom ($\mathcal{O}_I$})\\
This operator adds a new atom to a rule that uses an entity for one argument and shares the other argument (variable or entity) with the rule. 
\item \textbf{Add Closing Atom ($\mathcal{O}_C$})\\
This operator adds a new atom to a rule so that both of its arguments are shared with the rule. 
\end{enumerate}
By repeated application of these operators, we can generate the entire space of rules as defined in Section~\ref{sec:preliminaries}. The operators generate even more rules than those we are interested in, because they also produce rules that are not closed. An alternative set of operators could consist of $\mathcal{O}_D$ and an operator for instantiation. But these operators would not be monotonic, in the sense that an atom generated by one operator can be modified in the next step by the other operator. Therefore, we chose the above 3 operators as a canonic set. 

\paragraph{Algorithm} 
We mine rules with Algorithm \ref{rm}. The algorithm maintains a queue of rules, which initially just contains the empty rule. The algorithm iteratively dequeues a rule from the queue. If the rule is closed (see Section \ref{sec:preliminaries}), the rule is output, otherwise, it is not. Then, the algorithm applies all operators to the rule and adds the resulting rules to the queue (unless they are pruned out, s.b.). 
This process is repeated until the queue is empty. We parallelize this process by maintaining a centralized queue, from which the threads dequeue and enqueue. We do not feed predictions of the rules back into the KB. All measures (such as confidence and support) are always computed on the original KB.
\begin{algorithm}
\caption{Rule Mining}
\label{rm}
\begin{algorithmic}[1]
\Function{AMIE}{KB $\mathcal{K}$}
    \State $q = \langle [] \rangle$
	\State Execute in parallel:
	\While{$\neg q$\emph{.isEmpty}()}
	  \State $r = q.$\emph{dequeue}()
	  \If{$r$ is closed $\wedge$ $r$ is not pruned for output}
	    \State Output $r$
	  \EndIf
	  \ForAll{operators $o$}
	    \ForAll{rules $r' \in o(r)$}
		  \If{$r'$ is not pruned}
		    \State $q.$\emph{enqueue}$(r')$
		  \EndIf
		\EndFor
      \EndFor		
	\EndWhile    
\EndFunction
\end{algorithmic}
\end{algorithm}


\paragraph{Pruning} If executed naively, our algorithm will have prohibitively high run-times. The instantiation operator $\mathcal{O}_I$, in particular, generates atoms in the order of $|\mathcal{R}| \times |\mathcal{E}|$. We first observe that we are usually not interested in rules that cover only very few facts of the head relation.
% \comment{Katja}{Would a proper definition of what ''instances`` means in this context be useful?} 
% Fabian: switched to "facts of head relation"
Rules that cover, for example, less than 1\% of the facts of the head relation can safely assumed to be marginal. Therefore, we set $\theta=0.01$ as a lower bound for the head coverage. We observe that head coverage decreases monotonically as we add more atoms. This allows us to safely discard any rule that trespasses the threshold (Lines 11 and 12).
% \comment{Katja}{Maybe add the threshold itself to the pseudocode algorithm.}
% Fabian: Yes, this is an option. I wanted to keep the algorithm general, and outsource the definition of "pruning" to this paragraph here. This is because the algorithm is first discussed in generality in the previous section.

The monotonicity of head coverage gives us another opportunity to prune: If a rule $B_1 \wedge ... \wedge B_n \wedge B_{n+1} \Rightarrow H$ does not have larger confidence than the rule $B_1 \wedge ... \wedge B_n \Rightarrow H$, then we do not output the longer rule. This is because both the confidence and the head coverage of the longer rule are necessarily dominated by the shorter rule. This way, we can reduce the number of produced rules (Lines 6 and 7).

Last, we never enqueue a rule that is already in the queue. It is expensive to check two rules for equality. 
However, it is easy to compute measures such as head coverage, confidence, and PCA confidence for each rule. Two rules can only be equal if they have the same values for these measures. 
This restricts the rules that have to be checked. If a rule is duplicate, we do not enqueue it (Lines 11 and 12).
We can be sure that any potential duplicates will still be in the queue. This is because the length of the rules increases monotonically: When we dequeue a rule with $n$ atoms, no rule with $n+1$ atoms has ever been dequeued. Thus, when we apply the operators to the rule with $n$ atoms, and generate a rule with $n+1$ atoms, any potential duplicate of that new rule must be in the queue.

\ignore{
% Fabian: Problem solved. Thanks, Luis!
\comment{Fabian}{Problem: what if the duplicate rule has already been dequeued by some other thread?}
\comment{Katja}{Use a pointer over the queue that points to the next item to be dequeued by the next thread. The first positions correspond to rules that are currently considered by active threads. Remove the rule when the thread is finished. Check all rules for duplicates when trying to add a new rule to the queue.}
\comment{Luis}{We use a set that guarantees insertion order at iteration time (LinkedHashSet) to explore the space in a breath search fashion. That means that by the time the first of size n is dequeued, all rules of size n are already in the
queue and duplicates have been already pruned.}
}

\paragraph{Projection Queries} 
No matter what operator is applied in particular, the algorithm needs to choose a relation for the new atom that is added to the rule. In addition, 
the instantiation operator $\mathcal{O_I}$ also allows the choice of an entity. In order to select only relations and entities that will fulfill the head coverage constraint, we rely on the KB to answer \emph{projection queries}. These are queries of the form
\indented{SELECT $?x$ WHERE $H \wedge B_1 \wedge ... \wedge B_n$\\
HAVING COUNT($H$)$\geq k$}
where $B_1, ..., B_n$ are atoms and $k$ is a natural number. $H$ is the \emph{projection atom} on which we project. $?x$ is the \emph{selection variable}. It is a variable that appears in one or more atoms at the position of one of the arguments or at the position of the relation (as it is common in SPARQL\footnote{\url{http://www.w3.org/TR/rdf-sparql-query/}}). Such queries select an entity or relation $x$ such that the result of the query $H \wedge B_1 \wedge ... \wedge B_n$ on the KB contains more than $k$ distinct query answers for $H$.

\paragraph{Using Projection Queries} Projection queries allow us to select the relationship for the operators $\mathcal{O_D}$, $\mathcal{O_I}$, and $\mathcal{O_C}$ in such a way that the head coverage of the resulting rule is above $\theta$. 
 This works by firing a projection query of the form
\indented{SELECT $?r$ WHERE $H \wedge B_1 \wedge ... \wedge B_n \wedge\; ?r(X,Y)$\\
HAVING COUNT($H$)$\geq k$}
where $X$ and $Y$ are variables or constants, depending on the type of atoms that the operator generates. The results for $?r$ will be the relations that, once bound in the query, ensure that the support of the rule $B_1 \wedge ... \wedge B_n \wedge ?r(X,Y) \Rightarrow H$ is greater than $k$.
%\comment{Katja}{Why maintain? And when? The support is greater than a natural number $k$?}
% Fabian: I hope it's clearer now
If we choose $k$ equal to $\theta$ times the number of facts of the relation of $H$, then the head coverage of the resulting rules will be greater than $\theta$ -- which is what we want.
For the instantiation operator $\mathcal{O_I}$, we first fire a projection query to select relations, and then fire projection queries to retrieve entities.
This way, projection queries allow us to choose the relationships and entities for the operators in such a way that the head coverage for the new rules is guaranteed to be above $\theta$.
% \comment{Katja}{Should we add $\theta$ here explicitly?}
% Fabian: Theta was introduced previously, so we should be fine.
Next, we discuss how to implement projection queries efficiently. 


\subsection{Implementation}
\paragraph{SQL and SPARQL} Projection queries are essential for the efficiency of our system. Yet, standard database implementations do not provide special support for these types of queries. Assuming that the KB $\mathcal{K}$ is stored as a three-column table (i.e., each fact is a row with three elements), the projection query template in SQL would be:
\indented{SELECT $?x$ \\
FROM $\mathcal{K}$ AS H, $\mathcal{K}$ AS $B_1$, \dots $B_n$\\
WHERE $H.x_i$ = $B_j.x_m$, \dots \\
GROUP BY($H.x_1$, $H.x_r$, $H.x_2$)\\%, $?x$)\\
HAVING COUNT(*) $\geq k$}
where $?x$ is replaced with a reference to any of the introduced columns. The WHERE clause lists all variables that are shared between any two atoms in the rule, i.e., all join columns and conditions between atom tables. Since SELECT can only select variables that appear in the GROUP BY statement, the above template is for the case where $?x$ appears in $H$. The case where $?x$ does not appear in $H$ will require a nested query.
% \comment{Katja}{We need to think this through. Is it really worth the space? It does not really provide any new insight other that we (hopefully) know how to formulate SQL queries.}
% Fabian: I would leave it here to show how idiotic and slow this query will be
Our experience shows that already running the non-nested query on a database of a few million facts can easily take several minutes on an off-the-shelf RDBMS. Hence, efficient SPARQL engines such as RDF-3X \cite{rdf3x} are an alternative option. In SPARQL 1.1, the projection query template is: 
\indented{SELECT $?x$ \\
WHERE \{ \\
\hspace*{2ex}$H.x_1$, $H.x_r$, $H.x_2$ . \\
\hspace*{2ex}$B_1.x_1$, $B_1.x_r$, $B_1.x_2$ . \\
\hspace*{2ex}\dots \\
\hspace*{2ex}$B_n.x_1$, $B_n.x_r$, $B_n.x_2$ . \\
%\hspace*{2ex}HAVING COUNT($H$)$\geq k$\\
\} \\
GROUP BY $H.x_1$ $H.x_r$ $H.x_2$\\%, $?x$ \\
HAVING COUNT(*) $\geq k$
}
\ignore{
\comment{Katja}{We need to think about whether the addition of $?x$ as grouping variable will make a difference to what was originally meant -- because the original query further up only groups by $H$.}
\comment{Fabian}{Actually, $?x$ should not be in the grouping, no? We count by distinct $H$, even if $?x$ is not in $H$...}
\comment{Katja}{Per definition a query with a group by clause puts some constraints on what can appear in the select clause. The select clause can only enumerate columns that appear in the group by clause or aggregate functions over other columns -- no other plain columns are allowed. Which means in the above example that we cannot have $?x$ in the select clause if we do not add it to the group by clause! Also holds for all the other queries above!}
}
Again, this is only for the case where $?x$ appears in $H$. RDF-3X does not support aggregate functions in this way. Thus, we would need extensive postprocessing of query results to compute a projection query -- already in the case where $?x$ is in $H$.

\paragraph{In-Memory Database} We have implemented a vanilla in-memory database for semantic KBs. Our implementation indexes the facts aggressively with one index for each permutation of subject, relation, and object. Each index is a map from the first item to a map from the second item to a set of third items (e.g., a map from relations to a map from subjects to a set of objects). This allows retrieving the instantiations of a single atom in constant time. The existence of a query answer can be checked naively by selecting the atom with fewest instantiations, running through all of its instantiations, instantiating the remaining atoms accordingly, and repeating this process recursively until we find an instantiation of the query that appears in the KB. Select queries are similar.

\paragraph{Projection Queries} Algorithm \ref{algi} shows how we answer projection queries. The algorithm takes as input a selection variable $?x$, a projection atom $H=R(X,Y)$, remaining atoms $B_1, ... B_n$, a constant $k$, and a KB $\mathcal{K}$.
% \comment{Katja}{Why another definition of projection queries without back references? What exactly is a projection atom (not mentioned before)?}
% Fabian: I modified the definition above and this sentence. OK?
We first check whether $?x$ appears in the projection atom. If that is the case, we run through all instantiations of the projection atom, instantiate the query accordingly, and check for existence. Each existing instantiation increases the counter for the respective value of $?x$. We return all values whose counter exceeds $k$. If the selection variable does not appear in the projection atom, we iterate through all instantiations of the projection atom. We instantiate the query accordingly, and fire a SELECT query for $?x$. We increase the counter for each value of $?x$. We report all values whose counter exceeds $k$.

\paragraph{Summary} We have identified projection queries as the crucial type of queries for rule mining. Since standard database systems and standard SPARQL systems provide no specifically tuned support for these queries, we have implemented a vanilla in-memory database, which has specific support for projection queries. Our entire implementation is in Java.
%\comment{Katja}{I have my doubts that this matches the explanations in the previous paragraphs. Please check.}
%\comment{Fabian}{This is the way it's implemented. If anyone of us has doubts whether Algorithm \ref{algi} does what we think it does, please voice your concern!}

\begin{algorithm}
\caption{Answering Projection Queries}
\label{algi}
\begin{algorithmic}
\Function{SELECT}{$?x$, $R(X,Y) \wedge B_1 \wedge ... \wedge B_n$, $k$, $\mathcal{K}$}
    \State $map = \emptyset$
    \If {$~~R\equiv\; ?x ~~\vee~~ X\equiv\; ?x ~~\vee~~ Y\equiv\; ?x~~$}
	  \ForAll{instantiations $r(x,y)$ of $R(X,Y) \in \mathcal{K}$}
	    \State $q=B_1 \wedge ... \wedge B_n$
		\State In $q$, replace $R$ by $r$, $X$ by $x$, $Y$ by $y$
	    \If{exists instantiation $q \in \mathcal{K}$}
		\State $map($value of $?x)++$
		\EndIf
	  \EndFor
	\Else 
	  \ForAll{instantiations $r(x,y)$ of $R(X,Y) \in \mathcal{K}$}
	    \State $q=B_1 \wedge ... \wedge B_n$
		\State In $q$, replace $R$ by $r$, $X$ by $x$, $Y$ by $y$
	    \ForAll{$x \in $ {\small SELECT $?x$ FROM $\mathcal{K}$ WHERE $q$}}
		  \State $map(x)++$
		\EndFor
	  \EndFor
	\EndIf    
	\State \Return $\{ x : map(x)\geq k \}$
\EndFunction
\end{algorithmic}
\end{algorithm}
\ \\[-1cm]
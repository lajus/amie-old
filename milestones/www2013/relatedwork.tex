% !TEX root = main.tex

% good overview~\cite{KotsiatnisARSurvey}

\noindent We aim to mine rules of the form
\indented{
\emph{motherOf}$(m,c)$ $\wedge$ \emph{marriedTo}$(m,f) \Rightarrow$ \emph{fatherOf}$(f,c)$}
Technically, these are Horn rules on binary predicates. Rule mining has been an area of active research for the past couple of years. 
Some approaches mine association rules, some mine logical rules, others mine a schema for the KB, and again others use rule mining for application purposes.

% Fabian: List every approach, say why AMIE is either (1) tackling a different problem or (2) better.

\paragraph{Association Rule Mining} Association rules \cite{AgrImiSwa93} are mined on a list of \emph{transactions}. A transaction is a set of items. 
For example, in the context of sales analysis, a transaction is the set of products bought together by a customer in a specific event. 
The mined rules are of the form \{\emph{ElvisCD, ElvisBook}\} $\Rightarrow$ \emph{ElvisCostume}, meaning that people who bought an Elvis CD and an Elvis book usually also bought an Elvis costume. 
However, these are not the kind of rules that we aim to mine in this paper. We aim to mine Horn rules.

One problem for association rule mining is that for some applications the standard measurements for support and confidence do not produce good results. 
\cite{TanKumSri02} discusses a number of alternatives to measure the interestingness of a rule in general. 
Our approach is inspired by this work and we also make use of a language bias~\cite{AdeRaeBru95} to reduce the search space. 
% \comment{Chris}{make sure that you clearly define what exactly is your language bias}
% Fabian: We'll do that further down
%\cite{TanKumSri02} defines confidence and support measures, or interestingness measures of rules in general. We take inspiration from this work and also make use of a language bias~\cite{AdeRaeBru95} to reduce the search space.


\paragraph{Logical Rule Mining}
Sherlock \cite{SchEtzWel10} is an unsupervised ILP method to learn first-order Horn clauses from a set of extracted facts for a given target relation. 
It uses probabilistic graphical models (PGMs) to infer new facts. 
It tackles the noise of the extracted  facts by extensive filtering in a preprocessing step and by penalizing longer rules in the inference part. 
For mining the rules, Sherlock uses 2 heuristics: statistical significance and statistical relevance.
% (an alternative way to express Occam's razor).

The WARMR system \cite{DehToi99,DehToi00} mines patterns in databases that correspond to conjunctive queries. It uses a declarative language bias to reduce the search space. 
An extension of the system, WARMER~\cite{GoeVan02}, modified the approach to support a broader range of conjunctive queries and increase efficiency of search space exploration. 

ALEPH\footnote{\label{foot:aleph}\url{http://www.cs.ox.ac.uk/activities/machlearn/Aleph/aleph_toc.html}} is a general purpose ILP system, 
which implements Muggleton's Inverse Entailment algorithm~\cite{Muggleton95inverseentailment} in Prolog. 
It employs a variety of evaluation functions for the rules, and a variety of search strategies. 

These approaches are not tailored to deal with large KBs under the Open World Assumption. 
We compare our system, AMIE, to WARMR and ALEPH, which are the only ones available for download. 
Our experiments do not only show that these systems mine less sensible rules than AMIE, but also that it takes them much longer to do so. 


\paragraph{Expert Rule Mining}
% redundant: \cite{NebLla10}
Another rule mining approach over RDF data~\cite{NebBer12} was proposed to discover causal relations in RDF-based medical data. 
It requires a domain expert who defines targets and contexts of the mining process, so that the correct transactions are generated.
Our approach, in contrast, does not rely on the user to define any context or target. It works out-of-the-box.

%The work by~\cite{NebLla10,NebBer12} mines logical rules in RDF data.
%It requires users to define targets and contexts of the mining process. The approach was proposed to discover causal relations in RDF-based medical data. 
%In contrast to AMIE, this approach relies on the user to define context and target so that the correct transactions are generated. Thus, AMIE does not require any domain-expert users. 
%Our approach on the contrary, does not rely on the user to define any context or target, so that the correct transactions will be generated by the system, i.e. it does not require a domain-expert user. 

\paragraph{Generating Schemas} In this paper, we aim to generate Horn rules on a KB. Other approaches use rule mining to generate the schema or taxonomy of a KB.
\cite{CimHotSta04} applies clustering techniques based on context vectors and formal concept analysis to construct taxonomies. 
Other approaches use clustering~\cite{MaeZac02} and ILP-based approaches~\cite{DamFanEsp10}. For the friend-of-a-friend network on the Semantic Web, 
\cite{GriEdwPre04} applies clustering to identify classes of people and ILP to learn descriptions of these groups. 
Another example of an ILP-based approach is the DL-Learner~\cite{Leh09}, which has successfully been applied~\cite{HelLehAue09} to generate OWL class expressions from YAGO~\cite{SucKasWei07}. %large scale
As an alternative to ILP techniques, \cite{VoeNie11} propose a statistical method that does not require negative examples. 
%In general, however, approaches relying on inductive logic programming (ILP)
%~\cite{DamFanEsp10} or Formal Concept Analysis (FCA)~\cite{} 
%face the challenge of uncertain and noisy input data in the form of background knowledge and examples (open world assumption). Furthermore, the need for both positive and negative examples as well as scalability issues restrict the general applicability of ILP approaches~\cite{VoeNie11}. 
%In contrast to our approach, the proposed techniques aim at generating a schema for a given RDF repository, not logical rules in general.
In contrast to our approach, these techniques aim at generating a schema for a given RDF repository, not logical rules in general.

\paragraph{Learning Rules From Hybrid Sources} %\comment{}{these are new references}
% \cite{DBLP:conf/ekaw/dAmatoBS12} proposes to learn association rules from hybrid sources (RDBMS and Ontologies).  
%In this setting, there is incompleteness because of the open world semantics of the ontology and because of the possibly only partial overlap of constants between the ontology and the RDBMS.
%However, the way the size of this overlap affects the quality of the mined rules is not explored. 
%In contrast to our work, \cite{DBLP:conf/ekaw/dAmatoBS12} follows the standard association rule mining approach of making a closed world assumption. 
% The follow-up work 
\cite{DBLP:conf/semweb/dAmatoBS12} proposes to learn association rules from hybrid sources (RDBMS and Ontologies) under the OWA. For this purpose, the definition of frequency (and thus of support and confidence) is changed so that unknown statements contribute with half of the weight of the true statements. 
%However, the authors still not to compare how the quality of the mined rules changes according to the assumption used (OWA or CWA). 
Another approach~\cite{DBLP:journals/tplp/Lisi08} makes use of an ontology and a constraint Datalog program. The goal is to learn association rules at different levels of granularity w.r.t. the type hierarchy of the ontology.
%given a query involving both the ontology and the Datalog program. 
%However, in contrast to our work, \cite{DBLP:journals/tplp/Lisi08} also follows the closed world assumption.
% All of these approaches work on ontological rules, while our approach runs on pure RDFS KBs.
While these approaches focus more on the benefits of combining hybrid sources, our approach focuses on pure RDFS KBs.


\paragraph{Further Applications of Rule Mining}
\cite{JozLawLuk10} proposes an algorithm for frequent pattern mining in KBs that use DL-safe rules. 
%In this formalism, decidability is obtained by restricting the rules to DL-safe ones that are applicable only to instances explicitly known by name. 
Such KBs can be transformed into a disjunctive Datalog program, which allows seeing patterns as queries. 
%Patterns are defined as queries and information contained in the KB is used to span the search space. 
This approach does not mine the Horn rules that we aim at.
%\comment{Chris}{What is your sense? You haven't explained yet the form of the rules you are interested in}
%\comment{Fabian}{added example upfront. OK now? If not, please change it!}

Some approaches use rule mining for ontology merging and alignment~\cite{McgFikRic00,DavGuiBri07,NoyMus00}. 
The AROMA system~\cite{DavGuiBri07}, e.g., uses association rules on extracted terms to find subsumption relations between classes and properties of different ontologies. 
Again, these systems do not mine the kind of rules we are interested in.

%\comment{Relevant paper from Felix Neumann}
%Rule mining has been applied also in the context of schema re-engineering.

In~\cite{Abedjan:2012:ROW:2396761.2398467} association rules and frequency analysis are used to identify and classify common misusage patterns for relations in DBpedia.
In contrast to our work, this approach does not mine logical rules, but association rules on the co-occurrence of values.
Since RDF data can be seen as a graph, mining frequent subtrees~\cite{ChiMunNij04,KurKar01} is another related field of research. 
However, as the URIs of resources in knowledge bases are unique, these techniques are limited to mining frequent combinations of classes.
% after replacing resource URIs with their classes.

Several approaches, such as Markov Logic \cite {markovlogic} or URDF \cite{urdf} use Horn rules to perform reasoning. These approaches can be consumers of the rules we mine with AMIE.

\ignore{
%Sherlock: %They state that without negative examples it is difficult to distinguish correct rules from unsound rules. Based on these results, we expect that  developing measures or heuristics that will be able to guide the mining process successfully even when no negative examples are available will lead to a significant quality improvement and, therefore, it deserves further investigation.

Another application is to generate ontologies directly from natural language text. 
Several approaches have been proposed that apply association rule mining~\cite{MaeSta00,VilPerGod09} to generate non-taxonomic relations from text. 
\cite{JiaTanWan07} considers the problem of redundant or over-generalized patterns.
%One of the problems that association rule mining has to deal with is that the set of discovered rules might contain redundant or over-generalized patterns, thus techniques applying generalized association rule mining have been proposed~\cite{JiaTanWan07}. 
%\comment{Katja}{This work was developed to extract ontologies from natural language text, i.e., to create the schema -- but having had a look at the conferences they published this approach, we do not really have to cite them.}
% With such a different focus, the mined rules are not comparable to the logical rules we are looking for. 
Our goal is different, because we mine rules from KBs.

In \cite{TalWijMit12} typical temporal orderings between relations (e.g. $wonPrize(film,award)$ happens after $actedIn(person,film)$  ) 
are induced based on the narrative order of inferred mentions of these relations, averaged across many documents. 
Mining is applied in this context to find verbs that express certain relations.
Our work, in contrast, mines general logical rules.
%, thus applied in a different sense than AMIE applies association rule mining.
%\comment{Katja}{This is so far away from our topic that I would like to remove it.}
% Fabian: Let's keep it with Nicoleta's argument
}